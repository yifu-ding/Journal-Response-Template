@article{gawlikowski2023survey,
	title={A survey of uncertainty in deep neural networks},
	author={Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and others},
	journal={Artificial Intelligence Review},
	volume={56},
	number={Suppl 1},
	pages={1513--1589},
	year={2023},
	publisher={Springer}
}

@article{bi2018empirical,
	title={An empirical comparison on state-of-the-art multi-class imbalance learning algorithms and a new diversified ensemble learning scheme},
	author={Bi, Jingjun and Zhang, Chongsheng},
	journal={Knowledge-Based Systems},
	volume={158},
	pages={81--93},
	year={2018},
	publisher={Elsevier}
}

@article{johnson2019survey,
	title={Survey on deep learning with class imbalance},
	author={Johnson, Justin M and Khoshgoftaar, Taghi M},
	journal={Journal of Big Data},
	volume={6},
	number={1},
	pages={1--54},
	year={2019},
	publisher={Springer}
}

@inproceedings{zhang2021videolt,
	title={Videolt: Large-scale long-tailed video recognition},
	author={Zhang, Xing and Wu, Zuxuan and Weng, Zejia and Fu, Huazhu and Chen, Jingjing and Jiang, Yu-Gang and Davis, Larry S},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={7960--7969},
	year={2021}
}

@article{ganganwar2012overview,
	title={An overview of classification algorithms for imbalanced datasets},
	author={Ganganwar, Vaishali},
	journal={International Journal of Emerging Technology and Advanced Engineering},
	volume={2},
	number={4},
	pages={42--47},
	year={2012}
}

@article{cao2019learning,
	title={Learning imbalanced datasets with label-distribution-aware margin loss},
	author={Cao, Kaidi and Wei, Colin and Gaidon, Adrien and Arechiga, Nikos and Ma, Tengyu},
	journal={Advances in neural information processing systems},
	volume={32},
	year={2019}
}

@article{tomsett2020rapid,
	title={Rapid trust calibration through interpretable and uncertainty-aware AI},
	author={Tomsett, Richard and Preece, Alun and Braines, Dave and Cerutti, Federico and Chakraborty, Supriyo and Srivastava, Mani and Pearson, Gavin and Kaplan, Lance},
	journal={Patterns},
	volume={1},
	number={4},
	year={2020},
	publisher={Elsevier}
}

@inproceedings{liu2019large,
	title={Large-scale long-tailed recognition in an open world},
	author={Liu, Ziwei and Miao, Zhongqi and Zhan, Xiaohang and Wang, Jiayun and Gong, Boqing and Yu, Stella X},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={2537--2546},
	year={2019}
}

@inproceedings{qi2023text,
	title={Text Classification In The Wild: A Large-Scale Long-Tailed Name Normalization Dataset},
	author={Qi, Jiexing and Li, Shuhao and Guo, Zhixin and Huang, Yusheng and Zhou, Chenghu and Zhang, Weinan and Wang, Xinbing and Lin, Zhouhan},
	booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={1--5},
	year={2023},
	organization={IEEE}
}

@article{zhang2023deep,
	title={Deep long-tailed learning: A survey},
	author={Zhang, Yifan and Kang, Bingyi and Hooi, Bryan and Yan, Shuicheng and Feng, Jiashi},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	year={2023},
	publisher={IEEE}
}

@article{fu2022long,
	title={Long-tailed visual recognition with deep models: A methodological survey and evaluation},
	author={Fu, Yu and Xiang, Liuyu and Zahid, Yumna and Ding, Guiguang and Mei, Tao and Shen, Qiang and Han, Jungong},
	journal={Neurocomputing},
	year={2022},
	publisher={Elsevier}
}

@article{silva2023classifier,
	title={Classifier calibration: a survey on how to assess and improve predicted class probabilities},
	author={Silva Filho, Telmo and Song, Hao and Perello-Nieto, Miquel and Santos-Rodriguez, Raul and Kull, Meelis and Flach, Peter},
	journal={Machine Learning},
	pages={1--50},
	year={2023},
	publisher={Springer}
}

@article{AnExperimentalInvestigation,
	title={An experimental investigation of calibration techniques for imbalanced data},
	author={Huang, Lanlan and Zhao, Junkai and Zhu, Bing and Chen, Hao and Broucke, Seppe Vanden},
	journal={Ieee Access},
	volume={8},
	pages={127343--127352},
	year={2020},
	publisher={IEEE}
}

@article{gao2022comparative,
	title={A Comparative Study of Confidence Calibration in Deep Learning: From Computer Vision to Medical Imaging},
	author={Gao, Riqiang and Li, Thomas and Tang, Yucheng and Xu, Zhoubing and Kammer, Michael and Antic, Sanja L and Sandler, Kim and Moldonado, Fabien and Lasko, Thomas A and Landman, Bennett},
	journal={arXiv preprint arXiv:2206.08833},
	year={2022}
}

@article{zidonghua,
	title={A novel intelligent monitoring method for the closing time of the taphole of blast furnace based on two-stage classification},
	author={Jiang, Zhaohui and Dong, Jinzong and Pan, Dong and Wang, Tianyu and Gui, Weihua},
	journal={Engineering Applications of Artificial Intelligence},
	volume={120},
	pages={105849},
	year={2023},
	publisher={Elsevier}
}

@article{owais2024deep,
	title={Deep Learning for Integrated Origin--Destination Estimation and Traffic Sensor Location Problems},
	author={Owais, Mahmoud},
	journal={IEEE Transactions on Intelligent Transportation Systems},
	year={2024},
	publisher={IEEE}
}

@article{jiang2012calibrating,
	title={Calibrating predictive model estimates to support personalized medicine},
	author={Jiang, Xiaoqian and Osl, Melanie and Kim, Jihoon and Ohno-Machado, Lucila},
	journal={Journal of the American Medical Informatics Association},
	volume={19},
	number={2},
	pages={263--274},
	year={2012},
	publisher={BMJ Group}
}

@article{han2024balque,
	title={BALQUE: Batch active learning by querying unstable examples with calibrated confidence},
	author={Han, Yincheng and Liu, Dajiang and Shang, Jiaxing and Zheng, Linjiang and Zhong, Jiang and Cao, Weiwei and Sun, Hong and Xie, Wu},
	journal={Pattern Recognition},
	pages={110385},
	year={2024},
	publisher={Elsevier}
}

@inproceedings{li2023distilling,
	title={Distilling calibrated knowledge for stance detection},
	author={Li, Yingjie and Caragea, Cornelia},
	booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
	pages={6316--6329},
	year={2023}
}

@inproceedings{guoCalibration,
	title={On calibration of modern neural networks},
	author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
	booktitle={International conference on machine learning},
	pages={1321--1330},
	year={2017},
	organization={PMLR}
}

@inproceedings{geng2024survey,
	title={A Survey of Confidence Estimation and Calibration in Large Language Models},
	author={Geng, Jiahui and Cai, Fengyu and Wang, Yuxia and Koeppl, Heinz and Nakov, Preslav and Gurevych, Iryna},
	booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
	pages={6577--6595},
	year={2024}
}

@article{penso2024confidence,
	title={Confidence Calibration of a Medical Imaging Classification System that is Robust to Label Noise},
	author={Penso, Coby and Frenkel, Lior and Goldberger, Jacob},
	journal={IEEE Transactions on Medical Imaging},
	year={2024},
	publisher={IEEE}
}

@article{chen2024integrating,
	title={Integrating confidence calibration and adversarial robustness via adversarial calibration entropy},
	author={Chen, Yong and Hu, Peng and Yuan, Zhong and Peng, Dezhong and Wang, Xu},
	journal={Information Sciences},
	volume={668},
	pages={120532},
	year={2024},
	publisher={Elsevier}
}

@article{xiong2024proximity,
	title={Proximity-informed calibration for deep neural networks},
	author={Xiong, Miao and Deng, Ailin and Koh, Pang Wei W and Wu, Jiaying and Li, Shen and Xu, Jianqing and Hooi, Bryan},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	year={2024}
}

@article{munir2024cal,
	title={Cal-DETR: Calibrated Detection Transformer},
	author={Munir, Muhammad Akhtar and Khan, Salman H and Khan, Muhammad Haris and Ali, Mohsen and Shahbaz Khan, Fahad},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	year={2024}
}

@article{fernando2021dynamically,
	title={Dynamically weighted balanced loss: class imbalanced learning and confidence calibration of deep neural networks},
	author={Fernando, K Ruwani M and Tsokos, Chris P},
	journal={IEEE Transactions on Neural Networks and Learning Systems},
	volume={33},
	number={7},
	pages={2940--2951},
	year={2021},
	publisher={IEEE}
}

@article{song2022learning,
	title={Learning from noisy labels with deep neural networks: A survey},
	author={Song, Hwanjun and Kim, Minseok and Park, Dongmin and Shin, Yooju and Lee, Jae-Gil},
	journal={IEEE transactions on neural networks and learning systems},
	volume={34},
	number={11},
	pages={8135--8153},
	year={2022},
	publisher={IEEE}
}

@article{fortuin2022priors,
	title={Priors in bayesian deep learning: A review},
	author={Fortuin, Vincent},
	journal={International Statistical Review},
	volume={90},
	number={3},
	pages={563--591},
	year={2022},
	publisher={Wiley Online Library}
}

@article{ji2021survey,
	title={A survey on knowledge graphs: Representation, acquisition, and applications},
	author={Ji, Shaoxiong and Pan, Shirui and Cambria, Erik and Marttinen, Pekka and Philip, S Yu},
	journal={IEEE transactions on neural networks and learning systems},
	volume={33},
	number={2},
	pages={494--514},
	year={2021},
	publisher={IEEE}
}

@inproceedings{zhang2020mix,
	title={Mix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning},
	author={Zhang, Jize and Kailkhura, Bhavya and Han, T Yong-Jin},
	booktitle={International conference on machine learning},
	pages={11117--11128},
	year={2020},
	organization={PMLR}
}

@article{pan2017liftingnet,
	title={LiftingNet: A novel deep learning network with layerwise feature learning from noisy mechanical data for fault classification},
	author={Pan, Jun and Zi, Yanyang and Chen, Jinglong and Zhou, Zitong and Wang, Biao},
	journal={IEEE Transactions on Industrial Electronics},
	volume={65},
	number={6},
	pages={4973--4982},
	year={2017},
	publisher={IEEE}
}

@article{li2024trustworthy,
	title={Trustworthy Bayesian Deep Learning Framework for Uncertainty Quantification and Confidence Calibration: Application in Machinery Fault Diagnosis},
	author={Li, Hao and Jiao, Jinyang and Liu, Zongyang and Lin, Jing and Zhang, Tian and Liu, Hanyang},
	journal={Reliability Engineering \& System Safety},
	pages={110657},
	year={2024},
	publisher={Elsevier}
}

@article{zhang2022intelligent,
	title={Intelligent fault diagnosis of machines with small \& imbalanced data: A state-of-the-art review and possible extensions},
	author={Zhang, Tianci and Chen, Jinglong and Li, Fudong and Zhang, Kaiyu and Lv, Haixin and He, Shuilong and Xu, Enyong},
	journal={ISA transactions},
	volume={119},
	pages={152--171},
	year={2022},
	publisher={Elsevier}
}
@article{xu2023probabilistic,
	title={Probabilistic prognosis of wind turbine faults with feature selection and confidence calibration},
	author={Xu, Jian and Jiang, Xinxiong and Liao, Siyang and Ke, Deping and Sun, Yuanzhang and Yao, Liangzhong and Mao, Beilin},
	journal={IEEE Transactions on Sustainable Energy},
	volume={15},
	number={1},
	pages={52--67},
	year={2023},
	publisher={IEEE}
}

@article{zhu2023revisiting,
	title={Revisiting confidence estimation: Towards reliable failure prediction},
	author={Zhu, Fei and Zhang, Xu-Yao and Cheng, Zhen and Liu, Cheng-Lin},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	year={2023},
	publisher={IEEE}
}

@article{li2022novel,
	title={A novel severity calibration algorithm for defect detection by constructing maps},
	author={Li, Ying and Fan, Binbin and Ding, Weiping and Zhang, Weiping and Yin, Jianwei},
	journal={Information Sciences},
	volume={607},
	pages={1600--1616},
	year={2022},
	publisher={Elsevier}
}

@article{li2023efficient,
	title={An efficient defect detection method for nuclear-fuel rod grooves through weakly supervised learning},
	author={Li, Mengyuan and Chen, Ning and Suo, Xinyu and Yin, Shaohui and Liu, Jian},
	journal={Measurement},
	volume={222},
	pages={113708},
	year={2023},
	publisher={Elsevier}
}

@article{ni2024defect,
	title={Defect detection on multi-type rail surfaces via IoU decoupling and multi-information alignment},
	author={Ni, Xuefeng and Fieguth, Paul W and Ma, Ziji and Shi, Bo and Liu, Hongli},
	journal={Advanced Engineering Informatics},
	volume={62},
	pages={102717},
	year={2024},
	publisher={Elsevier}
}

@article{guo2021weld,
	title={Weld defect detection from imbalanced radiographic images based on contrast enhancement conditional generative adversarial network and transfer learning},
	author={Guo, Runyuan and Liu, Han and Xie, Guo and Zhang, Youmin},
	journal={IEEE Sensors Journal},
	volume={21},
	number={9},
	pages={10844--10853},
	year={2021},
	publisher={IEEE}
}

@article{nahar2025automated,
	title={Automated corner grading of trading cards: Defect identification and confidence calibration through deep learning},
	author={Nahar, Lutfun and Islam, Md Saiful and Awrangjeb, Mohammad and Verhoeve, Rob},
	journal={Computers in Industry},
	volume={164},
	pages={104187},
	year={2025},
	publisher={Elsevier}
}

@article{al2022ramifications,
	title={Ramifications of incorrect image segmentations; emphasizing on the potential effects on deep learning methods failure},
	author={Al-Dmour, Hayat},
	journal={Journal of Big Data},
	volume={9},
	number={1},
	pages={71},
	year={2022},
	publisher={Springer}
}

@article{richens2020improving,
	title={Improving the accuracy of medical diagnosis with causal machine learning},
	author={Richens, Jonathan G and Lee, Ciar{\'a}n M and Johri, Saurabh},
	journal={Nature communications},
	volume={11},
	number={1},
	pages={3923},
	year={2020},
	publisher={Nature Publishing Group UK London}
}

@article{sambyal2023understanding,
	title={Understanding calibration of deep neural networks for medical image classification},
	author={Sambyal, Abhishek Singh and Niyaz, Usma and Krishnan, Narayanan C and Bathula, Deepti R},
	journal={Computer Methods and Programs in Biomedicine},
	volume={242},
	pages={107816},
	year={2023},
	publisher={Elsevier}
}

@article{wang2021multiple,
	title={A multiple combined method for rebalancing medical data with class imbalances},
	author={Wang, Yun-Chun and Cheng, Ching-Hsue},
	journal={Computers in Biology and Medicine},
	volume={134},
	pages={104527},
	year={2021},
	publisher={Elsevier}
}

@article{salmi2024handling,
	title={Handling imbalanced medical datasets: review of a decade of research},
	author={Salmi, Mabrouka and Atif, Dalia and Oliva, Diego and Abraham, Ajith and Ventura, Sebastian},
	journal={Artificial Intelligence Review},
	volume={57},
	number={10},
	pages={273},
	year={2024},
	publisher={Springer}
}

@article{du2023adaptive,
	title={An adaptive deep metric learning loss function for class-imbalance learning via intraclass diversity and interclass distillation},
	author={Du, Jie and Zhang, Xiaoci and Liu, Peng and Vong, Chi-Man and Wang, Tianfu},
	journal={IEEE Transactions on Neural Networks and Learning Systems},
	year={2023},
	publisher={IEEE}
}

@article{ileberi2022machine,
	title={A machine learning based credit card fraud detection using the GA algorithm for feature selection},
	author={Ileberi, Emmanuel and Sun, Yanxia and Wang, Zenghui},
	journal={Journal of Big Data},
	volume={9},
	number={1},
	pages={24},
	year={2022},
	publisher={Springer}
}

@article{ryman2018artificial,
	title={How Artificial Intelligence and machine learning research impacts payment card fraud detection: A survey and industry benchmark},
	author={Ryman-Tubb, Nick F and Krause, Paul and Garn, Wolfgang},
	journal={Engineering Applications of Artificial Intelligence},
	volume={76},
	pages={130--157},
	year={2018},
	publisher={Elsevier}
}

@article{habibpour2023uncertainty,
	title={Uncertainty-aware credit card fraud detection using deep learning},
	author={Habibpour, Maryam and Gharoun, Hassan and Mehdipour, Mohammadreza and Tajally, AmirReza and Asgharnezhad, Hamzeh and Shamsi, Afshar and Khosravi, Abbas and Nahavandi, Saeid},
	journal={Engineering Applications of Artificial Intelligence},
	volume={123},
	pages={106248},
	year={2023},
	publisher={Elsevier}
}

@article{li2021hybrid,
	title={A hybrid method with dynamic weighted entropy for handling the problem of class imbalance with overlap in credit card fraud detection},
	author={Li, Zhenchuan and Huang, Mian and Liu, Guanjun and Jiang, Changjun},
	journal={Expert Systems with Applications},
	volume={175},
	pages={114750},
	year={2021},
	publisher={Elsevier}
}

@article{ning2024exploiting,
	title={Exploiting Meta-Learned Confidences for Imbalanced Multilabel Learning},
	author={Ning, Zhihan and Jiang, Zhixing and Zhang, David},
	journal={IEEE Transactions on Neural Networks and Learning Systems},
	year={2024},
	publisher={IEEE}
}

@article{wu2020comprehensive,
	title={A comprehensive survey on graph neural networks},
	author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
	journal={IEEE transactions on neural networks and learning systems},
	volume={32},
	number={1},
	pages={4--24},
	year={2020},
	publisher={IEEE}
}

@article{li2021survey,
	title={A survey of convolutional neural networks: analysis, applications, and prospects},
	author={Li, Zewen and Liu, Fan and Yang, Wenjie and Peng, Shouheng and Zhou, Jun},
	journal={IEEE transactions on neural networks and learning systems},
	volume={33},
	number={12},
	pages={6999--7019},
	year={2021},
	publisher={IEEE}
}

@article{zhang2023survey,
	title={A survey on learning to reject},
	author={Zhang, Xu-Yao and Xie, Guo-Sen and Li, Xiuli and Mei, Tao and Liu, Cheng-Lin},
	journal={Proceedings of the IEEE},
	volume={111},
	number={2},
	pages={185--215},
	year={2023},
	publisher={IEEE}
}

@article{li2021low,
	title={Low-light image and video enhancement using deep learning: A survey},
	author={Li, Chongyi and Guo, Chunle and Han, Linghao and Jiang, Jun and Cheng, Ming-Ming and Gu, Jinwei and Loy, Chen Change},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={44},
	number={12},
	pages={9396--9416},
	year={2021},
	publisher={IEEE}
}

@article{gordon2022data,
	title={Data Augmentation for Compositional Data: Advancing Predictive Models of the Microbiome},
	author={Gordon-Rodriguez, Elliott and Quinn, Thomas and Cunningham, John P},
	journal={Advances in Neural Information Processing Systems},
	volume={35},
	pages={20551--20565},
	year={2022}
}

@article{gong2022vqamix,
	title={VQAMix: Conditional triplet mixup for medical visual question answering},
	author={Gong, Haifan and Chen, Guanqi and Mao, Mingzhi and Li, Zhen and Li, Guanbin},
	journal={IEEE Transactions on Medical Imaging},
	volume={41},
	number={11},
	pages={3332--3343},
	year={2022},
	publisher={IEEE}
}

@inproceedings{wu2023towards,
	title={Towards reliable rare category analysis on graphs via individual calibration},
	author={Wu, Longfeng and Lei, Bowen and Xu, Dongkuan and Zhou, Dawei},
	booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	pages={2629--2638},
	year={2023}
}

@inproceedings{xu2023learning,
	title={Learning Imbalanced Data with Vision Transformers},
	author={Xu, Zhengzhuo and Liu, Ruikang and Yang, Shuo and Chai, Zenghao and Yuan, Chun},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={15793--15803},
	year={2023}
}

@article{yeung2023calibrating,
	title={Calibrating the Dice loss to handle neural network overconfidence for biomedical image segmentation},
	author={Yeung, Michael and Rundo, Leonardo and Nan, Yang and Sala, Evis and Sch{\"o}nlieb, Carola-Bibiane and Yang, Guang},
	journal={Journal of Digital Imaging},
	volume={36},
	number={2},
	pages={739--752},
	year={2023},
	publisher={Springer}
}

@article{lecun1998gradient,
	title={Gradient-based learning applied to document recognition},
	author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
	journal={Proceedings of the IEEE},
	volume={86},
	number={11},
	pages={2278--2324},
	year={1998},
	publisher={Ieee}
}

@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}

@article{xu2021towards,
	title={Towards calibrated model for long-tailed visual recognition from prior perspective},
	author={Xu, Zhengzhuo and Chai, Zenghao and Yuan, Chun},
	journal={Advances in Neural Information Processing Systems},
	volume={34},
	pages={7139--7152},
	year={2021}
}

@inproceedings{mitigating,
	title={Mitigating bias in calibration error estimation},
	author={Roelofs, Rebecca and Cain, Nicholas and Shlens, Jonathon and Mozer, Michael C},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={4036--4054},
	year={2022},
	organization={PMLR}
}

@inproceedings{aimar2023balanced,
	title={Balanced Product of Calibrated Experts for Long-Tailed Recognition},
	author={Aimar, Emanuel Sanchez and Jonnarth, Arvi and Felsberg, Michael and Kuhlmann, Marco},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={19967--19977},
	year={2023}
}

@article{guilbert2024calibration,
	title={Calibration methods in imbalanced binary classification},
	author={Guilbert, Th{\'e}o and Caelen, Olivier and Chirita, Andrei and Saerens, Marco},
	journal={Annals of Mathematics and Artificial Intelligence},
	pages={1--34},
	year={2024},
	publisher={Springer}
}

@article{patel2020multi,
	title={Multi-class uncertainty calibration via mutual information maximization-based binning},
	author={Patel, Kanil and Beluch, William and Yang, Bin and Pfeiffer, Michael and Zhang, Dan},
	journal={arXiv preprint arXiv:2006.13092},
	year={2020}
}

@inproceedings{zhong2021improving,
	title={Improving calibration for long-tailed recognition},
	author={Zhong, Zhisheng and Cui, Jiequan and Liu, Shu and Jia, Jiaya},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={16489--16498},
	year={2021}
}

@article{jung2023scaling,
	title={Scaling of Class-wise Training Losses for Post-hoc Calibration},
	author={Jung, Seungjin and Seo, Seungmo and Jeong, Yonghyun and Choi, Jongwon},
	journal={arXiv preprint arXiv:2306.10989},
	year={2023}
}

@inproceedings{huang2017densely,
	title={Densely connected convolutional networks},
	author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4700--4708},
	year={2017}
}

@inproceedings{li2022trustworthy,
	title={Trustworthy long-tailed classification},
	author={Li, Bolian and Han, Zongbo and Li, Haining and Fu, Huazhu and Zhang, Changqing},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={6970--6979},
	year={2022}
}

@ARTICLE{franchi2023encoding,
	author={Franchi, Gianni and Bursuc, Andrei and Aldea, Emanuel and Dubuisson, SÃ©verine and Bloch, Isabelle},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={Encoding the Latent Posterior of Bayesian Neural Networks for Uncertainty Quantification}, 
	year={2024},
	volume={46},
	number={4},
	pages={2027-2040},
	keywords={Training;Bayes methods;Uncertainty;Correlation;Task analysis;Gaussian distribution;Computational efficiency;Uncertainty estimation;deep neural network ensembles;Bayesian neural network},
	doi={10.1109/TPAMI.2023.3328829}}

@inproceedings{galdran2023multi,
	title={Multi-Head Multi-Loss Model Calibration},
	author={Galdran, Adrian and Verjans, Johan W and Carneiro, Gustavo and Gonz{\'a}lez Ballester, Miguel A},
	booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
	pages={108--117},
	year={2023},
	organization={Springer}
}

@inproceedings{hong2021disentangling,
	title={Disentangling label distribution for long-tailed visual recognition},
	author={Hong, Youngkyu and Han, Seungju and Choi, Kwanghee and Seo, Seokjun and Kim, Beomsu and Chang, Buru},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={6626--6636},
	year={2021}
}

@inproceedings{hebbalaguppe2022stitch,
	title={A stitch in time saves nine: A train-time regularizing loss for improved neural network calibration},
	author={Hebbalaguppe, Ramya and Prakash, Jatin and Madan, Neelabh and Arora, Chetan},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={16081--16090},
	year={2022}
}

@inproceedings{chen2023transfer,
	title={Transfer Knowledge from Head to Tail: Uncertainty Calibration under Long-tailed Distribution},
	author={Chen, Jiahao and Su, Bing},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={19978--19987},
	year={2023}
}

@article{pan2021model,
	title={On model calibration for long-tailed object detection and instance segmentation},
	author={Pan, Tai-Yu and Zhang, Cheng and Li, Yandong and Hu, Hexiang and Xuan, Dong and Changpinyo, Soravit and Gong, Boqing and Chao, Wei-Lun},
	journal={Advances in Neural Information Processing Systems},
	volume={34},
	pages={2529--2542},
	year={2021}
}

@article{wang2023predicting,
	title={Predicting neural network confidence using high-level feature distance},
	author={Wang, Jie and Ai, Jun and Lu, Minyan and Liu, Jingyu and Wu, Zili},
	journal={Information and Software Technology},
	volume={159},
	pages={107214},
	year={2023},
	publisher={Elsevier}
}

@inproceedings{nyberg2021reliably,
	title={Reliably calibrated isotonic regression},
	author={Nyberg, Otto and Klami, Arto},
	booktitle={Pacific-Asia Conference on Knowledge Discovery and Data Mining},
	pages={578--589},
	year={2021},
	organization={Springer}
}

@ARTICLE{li2024multi,
	author={Li, Shuxian and Song, Liyan and Wu, Xiaoyu and Hu, Zheng and Cheung, Yiu-ming and Yao, Xin},
	journal={IEEE Transactions on Knowledge and Data Engineering}, 
	title={Multi-Class Imbalance Classification Based on Data Distribution and Adaptive Weights}, 
	year={2024},
	volume={36},
	number={10},
	pages={5265-5279},
	keywords={Training;Ensemble learning;Costs;Computer science;Linear programming;Learning systems;Classification algorithms;Multi-class imbalance classification;ensembles;AdaBoost;adaptive weight;data density},
	doi={10.1109/TKDE.2024.3384961}}

@article{zhang2024entropy,
	title={Entropy-Based re-sampling method on SAR class imbalance target detection},
	author={Zhang, Chong-Qi and Deng, Yao and Chong, Ming-Zhe and Zhang, Zi-Wen and Tan, Yun-Hua},
	journal={ISPRS Journal of Photogrammetry and Remote Sensing},
	volume={209},
	pages={432--447},
	year={2024},
	publisher={Elsevier}
}

@article{wang2024imwmote,
	title={IMWMOTE: A novel oversampling technique for fault diagnosis in heterogeneous imbalanced data},
	author={Wang, Jiaxin and Wei, Jianan and Huang, Haisong and Wen, Long and Yuan, Yage and Chen, Hualin and Wu, Rui and Wu, Jinxing},
	journal={Expert Systems with Applications},
	volume={251},
	pages={123987},
	year={2024},
	publisher={Elsevier}
}

@ARTICLE{tian2024intrinsic,
	author={Tian, Jialin and Saddik, Abdulmotaleb El and Xu, Xing and Li, Dongshuai and Cao, Zuo and Shen, Heng Tao},
	journal={IEEE Transactions on Neural Networks and Learning Systems}, 
	title={Intrinsic Consistency Preservation With Adaptively Reliable Samples for Source-Free Domain Adaptation}, 
	year={2024},
	volume={},
	number={},
	pages={1-12},
	keywords={Reliability;Training;Task analysis;Adaptation models;Data models;Standards;Data privacy;Domain adaptation;domain and label shift;imbalanced distribution;source-free data},
	doi={10.1109/TNNLS.2024.3362948}}

@ARTICLE{liu2024sar,
	author={Liu, Yingbing and Yan, Gang and Ma, Fei and Zhou, Yongsheng and Zhang, Fan},
	journal={IEEE Transactions on Geoscience and Remote Sensing}, 
	title={SAR Ship Detection Based on Explainable Evidence Learning Under Intraclass Imbalance}, 
	year={2024},
	volume={62},
	number={},
	pages={1-15},
	keywords={Uncertainty;Marine vehicles;Feature extraction;Training;Data models;Object detection;Radar polarimetry;Contrastive learning;evidence learning;intraclass imbalance;synthetic aperture radar (SAR) ship detection},
	doi={10.1109/TGRS.2024.3373668}}

@ARTICLE{ning2024combat,
	author={Ning, Zhihan and Jiang, Zhixing and Zhang, David},
	journal={IEEE Transactions on Neural Networks and Learning Systems}, 
	title={To Combat Multiclass Imbalanced Problems by Aggregating Evolutionary Hierarchical Classifiers}, 
	year={2024},
	volume={},
	number={},
	pages={1-15},
	keywords={Genetic algorithms;Costs;Biological cells;Training;Feature extraction;Forestry;Aggregates;Genetic algorithms (GAs);hierarchical classification;imbalanced data;machine learning;multiclassification},
	doi={10.1109/TNNLS.2024.3383672}}

@inproceedings{devi2020review,
	title={A review on solution to class imbalance problem: Undersampling approaches},
	author={Devi, Debashree and Biswas, Saroj K and Purkayastha, Biswajit},
	booktitle={2020 international conference on computational performance evaluation (ComPE)},
	pages={626--631},
	year={2020},
	organization={IEEE}
}

@article{hoyos2021relevant,
	title={Relevant information undersampling to support imbalanced data classification},
	author={Hoyos-Osorio, J and Alvarez-Meza, A and Daza-Santacoloma, Genaro and Orozco-Gutierrez, A and Castellanos-Dominguez, Germ{\'a}n},
	journal={Neurocomputing},
	volume={436},
	pages={136--146},
	year={2021},
	publisher={Elsevier}
}

@ARTICLE{yan2022spatial,
	author={Yan, Yuanting and Zhu, Yuanwei and Liu, Ruiqing and Zhang, Yiwen and Zhang, Yanping and Zhang, Ling},
	journal={IEEE Transactions on Knowledge and Data Engineering}, 
	title={Spatial Distribution-Based Imbalanced Undersampling}, 
	year={2023},
	volume={35},
	number={6},
	pages={6376-6391},
	keywords={Training;Costs;Biological neural networks;Machine learning algorithms;Clustering algorithms;Signal processing algorithms;Proposals;Undersampling;imbalance;local pattern;sphere neighborhood;ensemble learning},
	doi={10.1109/TKDE.2022.3161537}}

@article{wang2020entropy,
	title={Entropy and confidence-based undersampling boosting random forests for imbalanced problems},
	author={Wang, Zhe and Cao, Chenjie and Zhu, Yujin},
	journal={IEEE transactions on neural networks and learning systems},
	volume={31},
	number={12},
	pages={5178--5191},
	year={2020},
	publisher={IEEE}
}

@article{ng2020hashing,
	title={Hashing-based undersampling ensemble for imbalanced pattern classification problems},
	author={Ng, Wing WY and Xu, Shichao and Zhang, Jianjun and Tian, Xing and Rong, Tongwen and Kwong, Sam},
	journal={IEEE Transactions on Cybernetics},
	volume={52},
	number={2},
	pages={1269--1279},
	year={2020},
	publisher={IEEE}
}

@ARTICLE{dablain2022deepsmote,
	author={Dablain, Damien and Krawczyk, Bartosz and Chawla, Nitesh V.},
	journal={IEEE Transactions on Neural Networks and Learning Systems}, 
	title={DeepSMOTE: Fusing Deep Learning and SMOTE for Imbalanced Data}, 
	year={2023},
	volume={34},
	number={9},
	pages={6390-6404},
	keywords={Deep learning;Training;Data models;Visualization;Image reconstruction;Learning systems;Inspection;Class imbalance;deep learning;machine learning;oversampling;synthetic minority oversampling technique (SMOTE)},
	doi={10.1109/TNNLS.2021.3136503}}

@article{maldonado2022fw,
	title={FW-SMOTE: A feature-weighted oversampling approach for imbalanced classification},
	author={Maldonado, Sebasti{\'a}n and Vairetti, Carla and Fernandez, Alberto and Herrera, Francisco},
	journal={Pattern Recognition},
	volume={124},
	pages={108511},
	year={2022},
	publisher={Elsevier}
}

@article{liu2023noise,
	title={Noise-robust oversampling for imbalanced data classification},
	author={Liu, Yongxu and Liu, Yan and Bruce, XB and Zhong, Shenghua and Hu, Zhejing},
	journal={Pattern Recognition},
	volume={133},
	pages={109008},
	year={2023},
	publisher={Elsevier}
}

@article{li2021novel,
	title={A novel oversampling technique for class-imbalanced learning based on SMOTE and natural neighbors},
	author={Li, Junnan and Zhu, Qingsheng and Wu, Quanwang and Fan, Zhu},
	journal={Information Sciences},
	volume={565},
	pages={438--455},
	year={2021},
	publisher={Elsevier}
}

@article{lin2023towards,
	title={Towards hybrid over-and under-sampling combination methods for class imbalanced datasets: an experimental study},
	author={Lin, Cian and Tsai, Chih-Fong and Lin, Wei-Chao},
	journal={Artificial Intelligence Review},
	volume={56},
	number={2},
	pages={845--863},
	year={2023},
	publisher={Springer}
}

@inproceedings{koziarski2021csmoute,
	title={Csmoute: Combined synthetic oversampling and undersampling technique for imbalanced data classification},
	author={Koziarski, Micha{\l}},
	booktitle={2021 International Joint Conference on Neural Networks (IJCNN)},
	pages={1--8},
	year={2021},
	organization={IEEE}
}

@inproceedings{shamsudin2020combining,
	title={Combining oversampling and undersampling techniques for imbalanced classification: A comparative study using credit card fraudulent transaction dataset},
	author={Shamsudin, Haziqah and Yusof, Umi Kalsom and Jayalakshmi, Andal and Khalid, Mohd Nor Akmal},
	booktitle={2020 IEEE 16th International Conference on Control \& Automation (ICCA)},
	pages={803--808},
	year={2020},
	organization={IEEE}
}

@article{park2021combined,
	title={Combined oversampling and undersampling method based on slow-start algorithm for imbalanced network traffic},
	author={Park, Seunghyun and Park, Hyunhee},
	journal={Computing},
	volume={103},
	number={3},
	pages={401--424},
	year={2021},
	publisher={Springer}
}

@inproceedings{dal2015calibrating,
	title={Calibrating probability with undersampling for unbalanced classification},
	author={Dal Pozzolo, Andrea and Caelen, Olivier and Johnson, Reid A and Bontempi, Gianluca},
	booktitle={2015 IEEE symposium series on computational intelligence},
	pages={159--166},
	year={2015},
	organization={IEEE}
}

@article{platt1999probabilistic,
	title={Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods},
	author={Platt, John and others},
	journal={Advances in large margin classifiers},
	volume={10},
	number={3},
	pages={61--74},
	year={1999},
	publisher={Cambridge, MA}
}

@inproceedings{huo2022density,
	title={Density-Aware Personalized Training for Risk Prediction in Imbalanced Medical Data},
	author={Huo, Zepeng and Qian, Xiaoning and Huang, Shuai and Wang, Zhangyang and Mortazavi, Bobak J},
	booktitle={Machine Learning for Healthcare Conference},
	pages={101--122},
	year={2022},
	organization={PMLR}
}

@InProceedings{bellinger2021calibrated,
	author="Bellinger, Colin
	and Corizzo, Roberto
	and Japkowicz, Nathalie",
	editor="Soares, Carlos
	and Torgo, Luis",
	title="Calibrated Resampling for Imbalanced and Long-Tails in Deep Learning",
	booktitle="Discovery Science",
	year="2021",
	publisher="Springer International Publishing",
	address="Cham",
	pages="242--252",
	abstract="Long-tailed distributions and class imbalance are problems of significant importance in applied deep learning where trained models are exploited for decision support and decision automation in critical areas such as health and medicine, transportation and finance. The challenge of learning deep models from such data remains high, and the state-of-the-art solutions are typically data dependent and primarily focused on images. Important real-world problems, however, are much more diverse thus necessitating a general solution that can be applied to diverse data types. In this paper, we propose ReMix, a training technique that seamlessly leverages batch resampling, instance mixing and soft-labels to efficiently enable the induction of robust deep models from imbalanced and long-tailed datasets. Our results show that fully connected neural networks and Convolutional Neural Networks (CNNs) trained with ReMix generally outperform the alternatives according to the g-mean and are better calibrated according to the balanced Brier score.",
	isbn="978-3-030-88942-5"
}

@inproceedings{chou2020remix,
	title={Remix: rebalanced mixup},
	author={Chou, Hsin-Ping and Chang, Shih-Chieh and Pan, Jia-Yu and Wei, Wei and Juan, Da-Cheng},
	booktitle={Computer Vision--ECCV 2020 Workshops: Glasgow, UK, August 23--28, 2020, Proceedings, Part VI 16},
	pages={95--110},
	year={2020},
	organization={Springer}
}

@ARTICLE{pan2024enhanced,
	author={Pan, Haolin and Guo, Yong and Yu, Mianjie and Chen, Jian},
	journal={IEEE Transactions on Image Processing}, 
	title={Enhanced Long-Tailed Recognition With Contrastive CutMix Augmentation}, 
	year={2024},
	volume={33},
	number={},
	pages={4215-4230},
	keywords={Tail;Dogs;Semantics;Training;Contrastive learning;Head;Data augmentation;Long-tailed recognition;data augmentation;contrastive learning},
	doi={10.1109/TIP.2024.3425148}}

@ARTICLE{chen2024instance,
	author={Chen, Jiahao and Su, Bing},
	journal={IEEE Transactions on Image Processing}, 
	title={Instance-Specific Semantic Augmentation for Long-Tailed Image Classification}, 
	year={2024},
	volume={33},
	number={},
	pages={2544-2557},
	keywords={Tail;Semantics;Head;Programmable logic arrays;Training;Image classification;Reliability;Long-tailed distribution;image classification;instance augmentation;imbalanced data},
	doi={10.1109/TIP.2024.3379929}}

@article{shin2024representation,
	title={Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning},
	author={Shin, Dong Geun and Chung, Hye Won},
	journal={arXiv preprint arXiv:2408.10676},
	year={2024}
}

@ARTICLE{xia2024uncertainty,
	author={Xia, Tong and Dang, Ting and Han, Jing and Qendro, Lorena and Mascolo, Cecilia},
	journal={IEEE Journal of Biomedical and Health Informatics}, 
	title={Uncertainty-Aware Health Diagnostics via Class-Balanced Evidential Deep Learning}, 
	year={2024},
	volume={28},
	number={11},
	pages={6417-6428},
	keywords={Uncertainty;Deep learning;Estimation;Medical diagnostic imaging;Data models;Reliability;Training;Uncertainty quantification;deep learning;trustworthy health diagnostics;class imbalance},
	doi={10.1109/JBHI.2024.3360002}}

@inproceedings{nnamdiconfidence,
	title={Confidence-Calibrated Clinical Decision Support System for Reliable Respiratory Disease Screening},
	author={Micky C. Nnamdi and J. Ben Tamo and Wenqi Shi and Vivek Chundru and Benoit Louis Marteau and Oankar R. Patil and May Dongmei Wang},
	booktitle={IEEE-EMBS International Conference on Biomedical and Health Informatics},
	year={2024},
	url={https://openreview.net/forum?id=chVymJKep2}
}

@article{yuksekgonul2024beyond,
	title={Beyond confidence: Reliable models should also consider atypicality},
	author={Yuksekgonul, Mert and Zhang, Linjun and Zou, James Y and Guestrin, Carlos},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	year={2024}
}

@inproceedings{
	popordanoskalascal,
	title={La{SC}al: Label-Shift Calibration without target labels},
	author={Teodora Popordanoska and Gorjan Radevski and Tinne Tuytelaars and Matthew B. Blaschko},
	booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
	year={2024},
	url={https://openreview.net/forum?id=TALJtWX7w4}
}

@inproceedings{Toplabel,
	title={Top-label calibration and multiclass-to-binary reductions},
	author={Chirag Gupta and Aaditya Ramdas},
	booktitle={International Conference on Learning Representations},
	year={2022},
	url={https://openreview.net/forum?id=WqoBaaPHS-}
}

@inproceedings{BeyondTemperatureScaling,
	author = {Kull, Meelis and Perello Nieto, Miquel and K\"{a}ngsepp, Markus and Silva Filho, Telmo and Song, Hao and Flach, Peter},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with Dirichlet calibration},
	url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/8ca01ea920679a0fe3728441494041b9-Paper.pdf},
	volume = {32},
	year = {2019}
}

@InProceedings{Evaluating,
	title = 	 {Evaluating model calibration in classification},
	author =       {Vaicenavicius, Juozas and Widmann, David and Andersson, Carl and Lindsten, Fredrik and Roll, Jacob and Sch\"{o}n, Thomas},
	booktitle = 	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
	pages = 	 {3459--3467},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = 	 {89},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {16--18 Apr},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v89/vaicenavicius19a/vaicenavicius19a.pdf},
	url = 	 {https://proceedings.mlr.press/v89/vaicenavicius19a.html},
	abstract = 	 {Probabilistic classifiers output a probability distribution on target classes rather than just a class prediction. Besides providing a clear separation of prediction and decision making, the main advantage of probabilistic models is their ability to represent uncertainty about predictions. In safety-critical applications, it is pivotal for a model to possess an adequate sense of uncertainty, which for probabilistic classifiers translates into outputting probability distributions that are consistent with the empirical frequencies observed from realized outcomes. A classifier with such a property is called calibrated. In this work, we develop a general theoretical calibration evaluation framework grounded in probability theory, and point out subtleties present in model calibration evaluation that lead to refined interpretations of existing evaluation techniques. Lastly, we propose new ways to quantify and visualize miscalibration in probabilistic classification, including novel multidimensional reliability diagrams.}
}

@misc{dong2024combining,
	title={Combining Priors with Experience: Confidence Calibration Based on Binomial Process Modeling}, 
	author={Jinzong Dong and Zhaohui Jiang and Dong Pan and Haoyang Yu},
	year={2024},
	eprint={2412.10658},
	archivePrefix={arXiv},
	primaryClass={stat.ME},
	url={https://arxiv.org/abs/2412.10658}, 
}

@misc{KScalibration,
	title={Calibration of Neural Networks using Splines}, 
	author={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},
	year={2021},
	eprint={2006.12800},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2006.12800}, 
}

@InProceedings{classAdaptive,
	author    = {Liu, Bingyuan and Rony, J\'er\^ome and Galdran, Adrian and Dolz, Jose and Ben Ayed, Ismail},
	title     = {Class Adaptive Network Calibration},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	month     = {June},
	year      = {2023},
	pages     = {16070-16079}
}

@inproceedings{muller2019does,
	author = {M\"{u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey E},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {When does label smoothing help?},
	url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/f1748d6b0fd9d439f71450117eba2725-Paper.pdf},
	volume = {32},
	year = {2019}
}

@inproceedings{
	Grathwohl2020Your,
	title={Your classifier is secretly an energy based model and you should treat it like one},
	author={Will Grathwohl and Kuan-Chieh Wang and Joern-Henrik Jacobsen and David Duvenaud and Mohammad Norouzi and Kevin Swersky},
	booktitle={International Conference on Learning Representations},
	year={2020},
	url={https://openreview.net/forum?id=Hkxzx0NtDB}
}

@InProceedings{Yang_2021_ICCV,
	author    = {Yang, Xiulong and Ji, Shihao},
	title     = {JEM++: Improved Techniques for Training JEM},
	booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
	month     = {October},
	year      = {2021},
	pages     = {6494-6503}
}

@InProceedings{Yang_2023_CVPR,
	author    = {Yang, Xiulong and Su, Qing and Ji, Shihao},
	title     = {Towards Bridging the Performance Gaps of Joint Energy-Based Models},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	month     = {June},
	year      = {2023},
	pages     = {15732-15741}
}

@ARTICLE{10423259,
	author={Hayashi, Hideaki},
	journal={IEEE Transactions on Neural Networks and Learning Systems}, 
	title={A Hybrid of Generative and Discriminative Models Based on the Gaussian-Coupled Softmax Layer}, 
	year={2024},
	volume={},
	number={},
	pages={1-11},
	keywords={Data models;Hybrid power systems;Artificial neural networks;Calibration;Semisupervised learning;Task analysis;Feature extraction;Confidence calibration;energy-based model (EBM);hybrid model;semi-supervised learning},
	doi={10.1109/TNNLS.2024.3358113}}

@article{BayesianBinning, 
	title={Obtaining Well Calibrated Probabilities Using Bayesian Binning}, 
	volume={29}, 
	url={https://ojs.aaai.org/index.php/AAAI/article/view/9602}, 
	DOI={10.1609/aaai.v29i1.9602}, 
	abstractNote={ &lt;p&gt; Learning probabilistic predictive models that are well calibrated is critical for many prediction and decision-making tasks in artificial intelligence. In this paper we present a new non-parametric calibration method called Bayesian Binning into Quantiles (BBQ) which addresses key limitations of existing calibration methods. The method post processes the output of a binary classification algorithm; thus, it can be readily combined with many existing classification algorithms. The method is computationally tractable, and empirically accurate, as evidenced by the set of experiments reported here on both real and simulated datasets. &lt;/p&gt; }, 
	number={1}, 
	journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
	author={Pakdaman Naeini, Mahdi and Cooper, Gregory and Hauskrecht, Milos}, 
	year={2015}, 
	month={Feb.} }

@article{joy2023sample, 
	title={Sample-Dependent Adaptive Temperature Scaling for Improved Calibration}, 
	volume={37}, 
	url={https://ojs.aaai.org/index.php/AAAI/article/view/26742}, 
	DOI={10.1609/aaai.v37i12.26742}, 
	abstractNote={It is now well known that neural networks can be wrong with high confidence in their predictions, leading to poor calibration. The most common post-hoc approach to compensate for this is to perform temperature scaling, which adjusts the confidences of the predictions on any input by scaling the logits by a fixed value. Whilst this approach typically improves the average calibration across the whole test dataset, this improvement typically reduces the individual confidences of the predictions irrespective of whether the classification of a given input is correct or incorrect. With this insight, we base our method on the observation that different samples contribute to the calibration error by varying amounts, with some needing to increase their confidence and others needing to decrease it. Therefore, for each input, we propose to predict a different temperature value, allowing us to adjust the mismatch between confidence and accuracy at a finer granularity. Our method is applied post-hoc, enabling it to be very fast with a negligible memory footprint and is applied to off-the-shelf pre-trained classifiers. We test our method on the ResNet50 and WideResNet28-10 architectures using the CIFAR10/100 and Tiny-ImageNet datasets, showing that producing per-data-point temperatures improves the expected calibration error across the whole test set.}, 
	number={12}, 
	journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
	author={Joy, Tom and Pinto, Francesco and Lim, Ser-Nam and Torr, Philip H.S. and Dokania, Puneet K.}, year={2023}, 
	month={Jun.}, 
	pages={14919-14926} }

@inproceedings{mixNmatch,
	title={Mix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning},
	author={Zhang, Jize and Kailkhura, Bhavya and Han, T Yong-Jin},
	booktitle={International conference on machine learning},
	pages={11117--11128},
	year={2020},
	organization={PMLR}
}

@inproceedings{zadrozny2001obtaining,
	title={Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers},
	author={Zadrozny, Bianca and Elkan, Charles},
	booktitle={Icml},
	volume={1},
	pages={609--616},
	year={2001}
}

@inproceedings{
	patel2021multiclass,
	title={Multi-Class Uncertainty Calibration via Mutual Information Maximization-based Binning},
	author={Kanil Patel and William H. Beluch and Bin Yang and Michael Pfeiffer and Dan Zhang},
	booktitle={International Conference on Learning Representations},
	year={2021},
	url={https://openreview.net/forum?id=AICNpd8ke-m}
}

@inproceedings{zadrozny2002transforming,
	author = {Zadrozny, Bianca and Elkan, Charles},
	title = {Transforming classifier scores into accurate multiclass probability estimates},
	year = {2002},
	isbn = {158113567X},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/775047.775151},
	doi = {10.1145/775047.775151},
	abstract = {Class membership probability estimates are important for many applications of data mining in which classification outputs are combined with other sources of information for decision-making, such as example-dependent misclassification costs, the outputs of other classifiers, or domain knowledge. Previous calibration methods apply only to two-class problems. Here, we show how to obtain accurate probability estimates for multiclass problems by combining calibrated binary probability estimates. We also propose a new method for obtaining calibrated two-class probability estimates that can be applied to any classifier that produces a ranking of examples. Using naive Bayes and support vector machine classifiers, we give experimental results from a variety of two-class and multiclass domains, including direct marketing, text categorization and digit recognition.},
	booktitle = {Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {694â699},
	numpages = {6},
	location = {Edmonton, Alberta, Canada},
	series = {KDD '02}
}

@article{intraOderPreserving,
	title={Intra order-preserving functions for calibration of multi-class neural networks},
	author={Rahimi, Amir and Shaban, Amirreza and Cheng, Ching-An and Hartley, Richard and Boots, Byron},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	pages={13456--13467},
	year={2020}
}

@inproceedings{rakka2024,
  author    = {Mariam Rakka and Jinhao Li and Guohao Dai and A. Eltawil and M. Fouda and Fadi J. Kurdahi},
  year      = {2024},
  title     = {SoftmAP: Software-Hardware Co-design for Integer-Only Softmax on Associative Processors},
  booktitle = {arXiv.org},
  doi       = {10.48550/arXiv.2411.17847},
}

@article{wang2023bitnet,
  title={Bitnet: Scaling 1-bit transformers for large language models},
  author={Wang, Hongyu and Ma, Shuming and Dong, Li and Huang, Shaohan and Wang, Huaijie and Ma, Lingxiao and Yang, Fan and Wang, Ruiping and Wu, Yi and Wei, Furu},
  journal={arXiv preprint arXiv:2310.11453},
  year={2023}
}



@article{shang2023pbllm,
  title={Pb-llm: Partially binarized large language models},
  author={Shang, Yuzhang and Yuan, Zhihang and Wu, Qiang and Dong, Zhen},
  journal={arXiv preprint arXiv:2310.00034},
  year={2023}
}



@inproceedings{huang2024billm,
  author    = {Wei Huang and Yangdong Liu and Haotong Qin and Ying Li and Shiming Zhang and Xianglong Liu and Michele Magno and Xiaojuan Qi},
  year      = {2024},
  title     = {BiLLM: Pushing the Limit of Post-Training Quantization for LLMs},
  booktitle = {International Conference on Machine Learning},
  doi       = {10.48550/arXiv.2402.04291},
}


@inproceedings{chen2024dbllm,
  author    = {Hong Chen and Chengtao Lv and Liang Ding and Haotong Qin and Xiabin Zhou and Yifu Ding and Xuebo Liu and Min Zhang and Jinyang Guo and Xianglong Liu and D. Tao},
  year      = {2024},
  title     = {DB-LLM: Accurate Dual-Binarization for Efficient LLMs},
  booktitle = {Annual Meeting of the Association for Computational Linguistics},
  doi       = {10.48550/arXiv.2402.11960},
}

@article{liu2022bit,
  title={Bit: Robustly binarized multi-distilled transformer},
  author={Liu, Zechun and Oguz, Barlas and Pappu, Aasish and Xiao, Lin and Yih, Scott and Li, Meng and Krishnamoorthi, Raghuraman and Mehdad, Yashar},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={14303--14316},
  year={2022}
}


@article{bai2020binarybert,
  title={Binarybert: Pushing the limit of bert quantization},
  author={Bai, Haoli and Zhang, Wei and Hou, Lu and Shang, Lifeng and Jin, Jing and Jiang, Xin and Liu, Qun and Lyu, Michael and King, Irwin},
  journal={arXiv preprint arXiv:2012.15701},
  year={2020}
}



@INPROCEEDINGS{mlbert,
  author={Nasab, Mahdi Mohammadi and Fakhire, Mahboube and Salehi, Mostafa E. and Modarresi, Mehdi},
  booktitle={2024 1st International Conference on Innovative Engineering Sciences and Technological Research (ICIESTR)}, 
  title={MLBERT: Multi-Level Fully Binarized BERT}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  keywords={Training;Adaptation models;Accuracy;Translation;Computational modeling;Neural networks;Memory management;Transformers;Real-time systems;Computational complexity;Deep Neural Network;BERT odels;Embedding Layers;Quantization;Multi-Level Binarization;Knowledge Distillation;Edge Devices},
  doi={10.1109/ICIESTR60916.2024.10798212}}


@inproceedings{xing2024bipft,
  title={Bipft: Binary pre-trained foundation transformer with low-rank estimation of binarization residual polynomials},
  author={Xing, Xingrun and Du, Li and Wang, Xinyuan and Zeng, Xianlin and Wang, Yequan and Zhang, Zheng and Zhang, Jiajun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={14},
  pages={16094--16102},
  year={2024}
}

@article{qin2022bibert,
  title={Bibert: Accurate fully binarized bert},
  author={Qin, Haotong and Ding, Yifu and Zhang, Mingyuan and Yan, Qinghua and Liu, Aishan and Dang, Qingqing and Liu, Ziwei and Liu, Xianglong},
  journal={arXiv preprint arXiv:2203.06390},
  year={2022}
}

@INPROCEEDINGS{bebert,
  author={Tian, Jiayi and Fang, Chao and Wang, Haonan and Wang, Zhongfeng},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Bebert: Efficient And Robust Binary Ensemble Bert}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  keywords={Training;Computational modeling;Bit error rate;Benchmark testing;Signal processing;Robustness;Natural language processing},
  doi={10.1109/ICASSP49357.2023.10096223}}



@inproceedings{chung-etal-2020-extremely,
    title = "Extremely Low Bit Transformer Quantization for On-Device Neural Machine Translation",
    author = "Chung, Insoo  and
      Kim, Byeongwook  and
      Choi, Yoonjung  and
      Kwon, Se Jung  and
      Jeon, Yongkweon  and
      Park, Baeseong  and
      Kim, Sangha  and
      Lee, Dongsoo",
    editor = "Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.433/",
    doi = "10.18653/v1/2020.findings-emnlp.433",
    pages = "4812--4826",
}



@InProceedings{binaryvit,
    author    = {Le, Phuoc-Hoan Charles and Li, Xinlin},
    title     = {BinaryViT: Pushing Binary Vision Transformers Towards Convolutional Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2023},
    pages     = {4664-4673}
}



@inproceedings{liu-2023-binary-and-ternary-nlg,
    title = "Binary and Ternary Natural Language Generation",
    author = "Liu, Zechun  and
      Oguz, Barlas  and
      Pappu, Aasish  and
      Shi, Yangyang  and
      Krishnamoorthi, Raghuraman",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.5/",
    doi = "10.18653/v1/2023.acl-long.5",
    pages = "65--77",
}


@article{zhu2024scalable,
  title={Scalable matmul-free language modeling},
  author={Zhu, Rui-Jie and Zhang, Yu and Abreu, Steven and Sifferman, Ethan and Sheaves, Tyler and Wang, Yiqiao and Richmond, Dustin and Shrestha, Sumit Bam and Zhou, Peng and Eshraghian, Jason K},
  journal={arXiv preprint arXiv:2406.02528},
  year={2024}
}



@article{llm-qat,
  title={Llm-qat: Data-free quantization aware training for large language models},
  author={Liu, Zechun and Oguz, Barlas and Zhao, Changsheng and Chang, Ernie and Stock, Pierre and Mehdad, Yashar and Shi, Yangyang and Krishnamoorthi, Raghuraman and Chandra, Vikas},
  journal={arXiv preprint arXiv:2305.17888},
  year={2023}
}


@inproceedings{ParetoQ,
  author    = {Zechun Liu and Changsheng Zhao and Hanxian Huang and Sijia Chen and Jing Zhang and Jiawei Zhao and Scott Roy and Lisa Jin and Yunyang Xiong and Yangyang Shi and Lin Xiao and Yuandong Tian and Bilge Soran and Raghuraman Krishnamoorthi and Tijmen Blankevoort and Vikas Chandra},
  year      = {2025},
  title     = {ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization},
  booktitle = {arXiv.org},
  doi       = {10.48550/arXiv.2502.02631},
}



@inproceedings{xiao2023smoothquant,
  title={Smoothquant: Accurate and efficient post-training quantization for large language models},
  author={Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Wu, Hao and Demouth, Julien and Han, Song},
  booktitle={International conference on machine learning},
  pages={38087--38099},
  year={2023},
  organization={PMLR}
}



@article{lin2024awq,
  title={Awq: Activation-aware weight quantization for on-device llm compression and acceleration},
  author={Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Chen, Wei-Ming and Wang, Wei-Chen and Xiao, Guangxuan and Dang, Xingyu and Gan, Chuang and Han, Song},
  journal={Proceedings of machine learning and systems},
  volume={6},
  pages={87--100},
  year={2024}
}



@article{shao2023omniquant,
  title={Omniquant: Omnidirectionally calibrated quantization for large language models},
  author={Shao, Wenqi and Chen, Mengzhao and Zhang, Zhaoyang and Xu, Peng and Zhao, Lirui and Li, Zhiqian and Zhang, Kaipeng and Gao, Peng and Qiao, Yu and Luo, Ping},
  journal={arXiv preprint arXiv:2308.13137},
  year={2023}
}


@article{gptq,
  title={Gptq: Accurate post-training quantization for generative pre-trained transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  journal={arXiv preprint arXiv:2210.17323},
  year={2022}
}



@INPROCEEDINGS{sole,
  author={Wang, Wenxun and Zhou, Shuchang and Sun, Wenyu and Sun, Peiqin and Liu, Yongpan},
  booktitle={2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD)}, 
  title={SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  keywords={Training;Quantization (signal);Energy conservation;Graphics processing units;Memory;Transformers;Natural language processing;Transformers;neural networks;hardware-software co-design;softmax;layer normalization},
  doi={10.1109/ICCAD57390.2023.10323725}}




@inproceedings{shen2020qbert,
  title={Q-bert: Hessian based ultra low precision quantization of bert},
  author={Shen, Sheng and Dong, Zhen and Ye, Jiayu and Ma, Linjian and Yao, Zhewei and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={8815--8821},
  year={2020}
}


@inproceedings{zafrir2019q8bert,
  title={Q8bert: Quantized 8bit bert},
  author={Zafrir, Ofir and Boudoukh, Guy and Izsak, Peter and Wasserblat, Moshe},
  booktitle={2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing-NeurIPS Edition (EMC2-NIPS)},
  pages={36--39},
  year={2019},
  organization={IEEE}
}




@article{zhang2020ternarybert,
  title={Ternarybert: Distillation-aware ultra-low bit bert},
  author={Zhang, Wei and Hou, Lu and Yin, Yichun and Shang, Lifeng and Chen, Xiao and Jiang, Xin and Liu, Qun},
  journal={arXiv preprint arXiv:2009.12812},
  year={2020}
}


@inproceedings{bai2021binarybert,
    title = "{B}inary{BERT}: Pushing the Limit of {BERT} Quantization",
    author = "Bai, Haoli  and
      Zhang, Wei  and
      Hou, Lu  and
      Shang, Lifeng  and
      Jin, Jin  and
      Jiang, Xin  and
      Liu, Qun  and
      Lyu, Michael  and
      King, Irwin",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    pages = "4334--4348",
}
